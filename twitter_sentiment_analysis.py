# -*- coding: utf-8 -*-
"""twitter_sentiment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bmrng4aQUVM3QIvs-tNOf5wIaZHObkjd
"""

# ğŸ“¦ 1. Import Required Libraries
import pandas as pd
import numpy as np
import re
import string
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

nltk.download('stopwords')
from nltk.corpus import stopwords

df = pd.read_csv('/content/twitter_training.csv.zip',header=None)

df.head()

df.columns = ['ID', 'Topic', 'Sentiment', 'Review']

df.columns

# ğŸ§¹ 2. Preprocessing Function
def preprocess_text(text):
    if not isinstance(text, str):
        text = str(text)

    text = text.lower()  # lowercase
    text = re.sub(r"http\S+|www\S+", '', text)  # remove URLs
    text = re.sub(r"@\w+", '', text)  # remove mentions
    text = re.sub(r"#\w+", '', text)  # remove hashtags
    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation
    text = re.sub(r"\d+", "", text)  # remove numbers
    text = re.sub(r'\s+', ' ', text).strip()  # remove extra spaces

    # remove stopwords
    stop_words = set(stopwords.words('english'))
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]

    return " ".join(tokens)


# ğŸ§¹ 4. Clean the Data
df['Review'] = df['Review'].astype(str).apply(preprocess_text)
df['Sentiment'] = df['Sentiment'].astype(str)

# ğŸ” 5. Encode Target Labels (Optional: if needed)
# If labels are not already like "Positive"/"Negative"
df['Sentiment'] = df['Sentiment'].str.capitalize()

# ğŸ¯ 6. Define Features and Labels
X = df['Review']
y = df['Sentiment']

# âœ‚ï¸ 7. Split into Train/Test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ”¤ 8. TF-IDF Vectorization
vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ğŸ¤– 9. Train Logistic Regression Model
model = LogisticRegression(max_iter=1000)
model.fit(X_train_vec, y_train)

# âœ… 10. Evaluate the Model
y_pred = model.predict(X_test_vec)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nâœ… Accuracy: {accuracy:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=['Negative', 'Positive'])
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
print("\nâœ… Classification Report:")
print(classification_report(y_test, y_pred))

# ğŸ”® 11. Prediction Function
def predict_sentiment(review):
    cleaned = preprocess_text(review)
    vectorized = vectorizer.transform([cleaned])
    prediction = model.predict(vectorized)
    return prediction[0]

# âœ¨ 12. Try Sample Predictions
print("ğŸ“¢ Example Predictions:\n")
print("ğŸ” Review: 'you are bad boy' â¡ï¸", predict_sentiment("you are bad boy"))
print("ğŸ” Review: 'I really love this phone!' â¡ï¸", predict_sentiment("I really love this phone!"))
print("ğŸ” Review: 'Worst experience ever!' â¡ï¸", predict_sentiment("Worst experience ever!"))

predict_sentiment("you are good boy")

predict_sentiment("this is pretty scared")