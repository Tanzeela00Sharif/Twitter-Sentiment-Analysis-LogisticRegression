ğŸ“Š Twitter Sentiment Analysis â€“ Logistic Regression Model
âœ… Project Summary Report

ğŸ” Objective
This project aims to build a Sentiment Analysis model to classify tweets as either Positive or Negative based on the textual content. It helps businesses understand customer feedback, social trends, or product opinions in real time using machine learning.
ğŸ“ Dataset
The dataset includes the following columns:
â€¢	ID â€“ Unique identifier for each tweet
â€¢	Topic â€“ Subject/topic related to the tweet (optional in modeling)
â€¢	Sentiment â€“ The labeled sentiment (Positive/Negative)
â€¢	Review â€“ Text content of the tweet or customer review
ğŸ› ï¸ Tools & Libraries Used
â€¢	Python
â€¢	Scikit-learn
â€¢	Pandas, Numpy
â€¢	Matplotlib, Seaborn
â€¢	TfidfVectorizer
ğŸ§¹ Data Preprocessing
The following steps were applied to clean and prepare the text data:
â€¢	Converted all reviews to lowercase
â€¢	Removed punctuation marks and special characters
â€¢	Removed stopwords (like "the", "is", "and", etc.)
â€¢	Tokenized the text and normalized spacing
â€¢	Used TF-IDF Vectorization (ngram_range=(1,2), stop words removed)

ğŸ§  Model Training
â€¢	Algorithm: Logistic Regression
â€¢	Vectorization: TF-IDF
â€¢	Train-Test Split: 80/20
â€¢	Training set transformed using TfidfVectorizer, and the same was applied to test and new data

âœ… Evaluation Results
Metric	Value
Accuracy	88.5%
Precision (Positive)	90%
Precision (Negative)	87%
F1-Score (Overall)	~88%
ğŸ“Œ Confusion Matrix:
[[4208  369]
 [ 621 3477]]
________________________________________
ğŸ” Model Testing Examples
Input Text	Predicted Sentiment
"you are bad boy"	âŒ Positive (Incorrect)
"I really love this phone!"	âœ… Positive
"Worst experience ever!"	âœ… Negative
Note: Early testing revealed bias in prediction due to TF-IDF mismatch during vectorization. Issue was resolved by using the same fitted vectorizer during both training and prediction.

ğŸ“ Deliverables
â€¢	Clean and modular Python code (.py or Jupyter notebook)
â€¢	PDF Report with evaluation results
â€¢	GitHub repository containing:
o	Code
o	Preprocessing functions
o	Vectorizer and model training steps
o	Test examples and predictions

ğŸ’¡ Key Learnings
â€¢	Importance of consistent TF-IDF vectorization across training and inference
â€¢	Handling text preprocessing for noisy social media content
â€¢	Logistic Regression as an effective baseline for sentiment classification

  

